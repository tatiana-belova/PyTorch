{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc342db6",
   "metadata": {},
   "source": [
    "# Домашнее задание №9\n",
    "\n",
    "Переписать загрузку данных с python функций на Dataset и Dataloader и применить сеть с attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3419f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c948efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "num_samples = 10000\n",
    "data_path = 'data/fra-eng/fra.txt'\n",
    "print_loss_n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d87d59ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslateDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_name=data_path, num_samples=num_samples):\n",
    "\n",
    "        texts = []\n",
    "        text_words = []\n",
    "\n",
    "        input_vocab = set()\n",
    "        output_vocab = set()\n",
    "        \n",
    "        print('Загружаем ', file_name)\n",
    "        \n",
    "        with open(file_name, 'r', encoding='utf-8') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "\n",
    "        for line in lines[:num_samples]:\n",
    "            input_text, output_text, _ = line.split('\\t')\n",
    "\n",
    "            texts.append((input_text, output_text))\n",
    "            \n",
    "            input_words = re.findall(r'\\w+', input_text) \n",
    "            output_words = re.findall(r'\\w+', output_text) \n",
    "            text_words.append((input_words, output_words))\n",
    "            \n",
    "            for word in input_words:\n",
    "                input_vocab.add(word)\n",
    "            for word in output_words:\n",
    "                output_vocab.add(word)\n",
    "    \n",
    "        input_vocab2index = {word: i+2 for i, word in enumerate(input_vocab)}\n",
    "        output_vocab2index = {word: i+2 for i, word in enumerate(output_vocab)}        \n",
    "\n",
    "        def ws2i(words, vocab):\n",
    "            indexes = [vocab.get(word, 0) for word in words] + [1]\n",
    "            return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
    "        \n",
    "        self.texts = texts\n",
    "        self.encoded_texts = [ (ws2i(p[0], input_vocab2index), ws2i(p[1], output_vocab2index)) for p in text_words ]\n",
    "        self.input_vocab2index = input_vocab2index\n",
    "        self.output_vocab2index = output_vocab2index\n",
    "        self.input_vocabulary_size = len(self.input_vocab2index) + 2\n",
    "        self.output_vocabulary_size = len(self.output_vocab2index) + 2\n",
    "        \n",
    "        print('Загружен ', file_name)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index] + self.texts[index]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5fcc14eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружаем  data/fra-eng/fra.txt\n",
      "Загружен  data/fra-eng/fra.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1022],\n",
       "         [   1]]),\n",
       " tensor([[3922],\n",
       "         [   1]]),\n",
       " 'Hi.',\n",
       " 'Salut !')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = TranslateDataset()\n",
    "ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "393c978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)\n",
    "\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=10):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        embedded_hidden = torch.cat((embedded[0], hidden[0]), 1)\n",
    "\n",
    "        attn_weights = self.attn(embedded_hidden)\n",
    "        \n",
    "        attn_weights = F.softmax(attn_weights, dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        #output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0af9e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=10):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[0]])\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    for di in range(target_length):\n",
    "        \n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        \n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        \n",
    "        decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "        \n",
    "        loss += criterion(decoder_output, target_tensor[di])\n",
    "        if decoder_input.item() == 1:\n",
    "            break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1c2cff3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== Эпоха 0 ====================\n",
      "(100) 5.4154\n",
      "(200) 5.1222\n",
      "(300) 5.6370\n",
      "(400) 4.0456\n",
      "(500) 3.5234\n",
      "(600) 4.1145\n",
      "(700) 3.6378\n",
      "(800) 3.8981\n",
      "(900) 4.2480\n",
      "(1000) 3.6808\n",
      "(1100) 4.1150\n",
      "(1200) 4.0673\n",
      "(1300) 4.0941\n",
      "(1400) 3.8393\n",
      "(1500) 3.8872\n",
      "(1600) 3.9260\n",
      "(1700) 3.6480\n",
      "(1800) 3.9480\n",
      "(1900) 3.6985\n",
      "(2000) 3.9410\n",
      "(2100) 3.5867\n",
      "(2200) 4.1149\n",
      "(2300) 3.8778\n",
      "(2400) 4.0312\n",
      "(2500) 3.9037\n",
      "(2600) 3.9700\n",
      "(2700) 3.8139\n",
      "(2800) 3.8772\n",
      "(2900) 3.7586\n",
      "(3000) 3.9776\n",
      "(3100) 3.5799\n",
      "(3200) 3.8271\n",
      "(3300) 3.9695\n",
      "(3400) 3.7598\n",
      "(3500) 3.6860\n",
      "(3600) 3.8502\n",
      "(3700) 3.7590\n",
      "(3800) 3.8219\n",
      "(3900) 3.9608\n",
      "(4000) 3.5760\n",
      "(4100) 3.6564\n",
      "(4200) 3.5464\n",
      "(4300) 3.6801\n",
      "(4400) 3.6075\n",
      "(4500) 3.6561\n",
      "(4600) 3.8032\n",
      "(4700) 3.5211\n",
      "(4800) 3.4753\n",
      "(4900) 3.6683\n",
      "(5000) 3.6893\n",
      "(5100) 3.7497\n",
      "(5200) 3.6908\n",
      "(5300) 3.5174\n",
      "(5400) 3.6350\n",
      "(5500) 3.7080\n",
      "(5600) 3.7867\n",
      "(5700) 3.4593\n",
      "(5800) 3.6339\n",
      "(5900) 3.6768\n",
      "(6000) 3.7534\n",
      "(6100) 3.5430\n",
      "(6200) 3.4145\n",
      "(6300) 3.7565\n",
      "(6400) 3.6783\n",
      "(6500) 3.6395\n",
      "(6600) 3.5592\n",
      "(6700) 3.7854\n",
      "(6800) 3.5755\n",
      "(6900) 3.7337\n",
      "(7000) 3.5576\n",
      "(7100) 3.8092\n",
      "(7200) 3.5965\n",
      "(7300) 3.7546\n",
      "(7400) 3.4333\n",
      "(7500) 3.5466\n",
      "(7600) 3.8201\n",
      "(7700) 3.5747\n",
      "(7800) 3.5972\n",
      "(7900) 3.7281\n",
      "(8000) 3.6009\n",
      "(8100) 3.4831\n",
      "(8200) 3.7234\n",
      "(8300) 3.5393\n",
      "(8400) 3.8099\n",
      "(8500) 3.6366\n",
      "(8600) 3.5896\n",
      "(8700) 3.5572\n",
      "(8800) 3.6408\n",
      "(8900) 3.5518\n",
      "(9000) 3.7406\n",
      "(9100) 3.4217\n",
      "(9200) 3.4937\n",
      "(9300) 3.6503\n",
      "(9400) 3.3244\n",
      "(9500) 3.6321\n",
      "(9600) 3.5736\n",
      "(9700) 3.6752\n",
      "(9800) 3.3734\n",
      "(9900) 3.6670\n",
      "(10000) 3.4419\n",
      "===================== Эпоха 1 ====================\n",
      "(100) 3.4151\n",
      "(200) 3.5298\n",
      "(300) 3.2998\n",
      "(400) 3.6456\n",
      "(500) 3.6823\n",
      "(600) 3.8205\n",
      "(700) 3.8068\n",
      "(800) 3.4695\n",
      "(900) 3.6545\n",
      "(1000) 3.3831\n",
      "(1100) 3.7343\n",
      "(1200) 3.5412\n",
      "(1300) 3.4339\n",
      "(1400) 3.6458\n",
      "(1500) 3.5418\n",
      "(1600) 3.5963\n",
      "(1700) 3.4668\n",
      "(1800) 3.4641\n",
      "(1900) 3.2989\n",
      "(2000) 3.6681\n",
      "(2100) 3.3874\n",
      "(2200) 3.7260\n",
      "(2300) 3.4579\n",
      "(2400) 3.2553\n",
      "(2500) 3.5429\n",
      "(2600) 3.5138\n",
      "(2700) 3.4626\n",
      "(2800) 3.7086\n",
      "(2900) 3.3901\n",
      "(3000) 3.4090\n",
      "(3100) 3.5133\n",
      "(3200) 3.3886\n",
      "(3300) 3.3803\n",
      "(3400) 3.5780\n",
      "(3500) 3.5432\n",
      "(3600) 3.3577\n",
      "(3700) 3.5156\n",
      "(3800) 3.2405\n",
      "(3900) 3.6262\n",
      "(4000) 3.4179\n",
      "(4100) 3.4928\n",
      "(4200) 3.3790\n",
      "(4300) 3.5596\n",
      "(4400) 3.3922\n",
      "(4500) 3.6112\n",
      "(4600) 3.3738\n",
      "(4700) 3.5695\n",
      "(4800) 3.3539\n",
      "(4900) 3.5300\n",
      "(5000) 3.4065\n",
      "(5100) 3.5548\n",
      "(5200) 3.4307\n",
      "(5300) 3.2519\n",
      "(5400) 3.5540\n",
      "(5500) 3.6953\n",
      "(5600) 3.3026\n",
      "(5700) 3.5039\n",
      "(5800) 3.6636\n",
      "(5900) 3.2740\n",
      "(6000) 3.3773\n",
      "(6100) 3.5587\n",
      "(6200) 3.3769\n",
      "(6300) 3.3356\n",
      "(6400) 3.3583\n",
      "(6500) 3.5304\n",
      "(6600) 3.4538\n",
      "(6700) 3.4093\n",
      "(6800) 3.4254\n",
      "(6900) 3.3665\n",
      "(7000) 3.5857\n",
      "(7100) 3.3553\n",
      "(7200) 3.5282\n",
      "(7300) 3.4518\n",
      "(7400) 3.4921\n",
      "(7500) 3.3402\n",
      "(7600) 3.4882\n",
      "(7700) 3.4964\n",
      "(7800) 3.2328\n",
      "(7900) 3.5042\n",
      "(8000) 3.3759\n",
      "(8100) 3.3183\n",
      "(8200) 3.4368\n",
      "(8300) 3.2204\n",
      "(8400) 3.5000\n",
      "(8500) 3.5787\n",
      "(8600) 3.4581\n",
      "(8700) 3.4445\n",
      "(8800) 3.3584\n",
      "(8900) 3.4762\n",
      "(9000) 3.3772\n",
      "(9100) 3.1962\n",
      "(9200) 3.3746\n",
      "(9300) 3.4856\n",
      "(9400) 3.4111\n",
      "(9500) 3.4014\n",
      "(9600) 3.4926\n",
      "(9700) 3.3458\n",
      "(9800) 3.4352\n",
      "(9900) 3.4286\n",
      "(10000) 3.2905\n",
      "===================== Эпоха 2 ====================\n",
      "(100) 3.1239\n",
      "(200) 3.3619\n",
      "(300) 3.2500\n",
      "(400) 3.4292\n",
      "(500) 3.5058\n",
      "(600) 3.2513\n",
      "(700) 3.2580\n",
      "(800) 3.6038\n",
      "(900) 2.9583\n",
      "(1000) 3.2899\n",
      "(1100) 3.2991\n",
      "(1200) 3.3961\n",
      "(1300) 3.3362\n",
      "(1400) 3.4463\n",
      "(1500) 3.2641\n",
      "(1600) 3.3508\n",
      "(1700) 3.4242\n",
      "(1800) 3.4380\n",
      "(1900) 3.3525\n",
      "(2000) 3.3113\n",
      "(2100) 3.2082\n",
      "(2200) 3.3373\n",
      "(2300) 3.3992\n",
      "(2400) 3.7192\n",
      "(2500) 3.2199\n",
      "(2600) 3.4596\n",
      "(2700) 3.3364\n",
      "(2800) 3.2638\n",
      "(2900) 3.3215\n",
      "(3000) 3.3463\n",
      "(3100) 3.2557\n",
      "(3200) 3.2952\n",
      "(3300) 3.2355\n",
      "(3400) 3.1713\n",
      "(3500) 3.1935\n",
      "(3600) 3.3456\n",
      "(3700) 3.3166\n",
      "(3800) 3.3656\n",
      "(3900) 3.3766\n",
      "(4000) 3.2553\n",
      "(4100) 3.5246\n",
      "(4200) 3.7152\n",
      "(4300) 3.5003\n",
      "(4400) 3.2813\n",
      "(4500) 3.3340\n",
      "(4600) 3.2051\n",
      "(4700) 3.4786\n",
      "(4800) 3.4201\n",
      "(4900) 3.2607\n",
      "(5000) 3.2845\n",
      "(5100) 3.2066\n",
      "(5200) 3.1518\n",
      "(5300) 3.5402\n",
      "(5400) 3.2894\n",
      "(5500) 3.1653\n",
      "(5600) 3.4404\n",
      "(5700) 3.2322\n",
      "(5800) 3.3481\n",
      "(5900) 3.5165\n",
      "(6000) 3.2547\n",
      "(6100) 3.3378\n",
      "(6200) 3.2425\n",
      "(6300) 3.2219\n",
      "(6400) 3.3085\n",
      "(6500) 3.3727\n",
      "(6600) 3.2214\n",
      "(6700) 3.1669\n",
      "(6800) 3.4377\n",
      "(6900) 3.2995\n",
      "(7000) 3.2575\n",
      "(7100) 3.2531\n",
      "(7200) 3.4592\n",
      "(7300) 3.3070\n",
      "(7400) 3.1887\n",
      "(7500) 3.1575\n",
      "(7600) 3.4812\n",
      "(7700) 3.2550\n",
      "(7800) 3.4024\n",
      "(7900) 3.1949\n",
      "(8000) 3.1171\n",
      "(8100) 3.3649\n",
      "(8200) 3.1414\n",
      "(8300) 3.4352\n",
      "(8400) 3.3869\n",
      "(8500) 3.2131\n",
      "(8600) 3.4049\n",
      "(8700) 3.1174\n",
      "(8800) 3.2530\n",
      "(8900) 3.2145\n",
      "(9000) 3.2967\n",
      "(9100) 3.2371\n",
      "(9200) 3.1252\n",
      "(9300) 3.2915\n",
      "(9400) 3.1883\n",
      "(9500) 3.2904\n",
      "(9600) 3.1930\n",
      "(9700) 3.3010\n",
      "(9800) 3.2989\n",
      "(9900) 3.3977\n",
      "(10000) 3.2651\n",
      "===================== Эпоха 3 ====================\n",
      "(100) 3.2003\n",
      "(200) 3.3703\n",
      "(300) 3.2915\n",
      "(400) 3.1937\n",
      "(500) 3.3023\n",
      "(600) 3.2169\n",
      "(700) 3.0910\n",
      "(800) 3.0883\n",
      "(900) 3.3310\n",
      "(1000) 3.1789\n",
      "(1100) 3.2633\n",
      "(1200) 3.1280\n",
      "(1300) 3.2607\n",
      "(1400) 3.3318\n",
      "(1500) 3.0092\n",
      "(1600) 3.2621\n",
      "(1700) 3.2086\n",
      "(1800) 3.1623\n",
      "(1900) 3.1404\n",
      "(2000) 3.2843\n",
      "(2100) 3.1039\n",
      "(2200) 3.0887\n",
      "(2300) 3.3277\n",
      "(2400) 3.3061\n",
      "(2500) 3.2275\n",
      "(2600) 3.1978\n",
      "(2700) 3.1625\n",
      "(2800) 3.3685\n",
      "(2900) 3.1986\n",
      "(3000) 3.2844\n",
      "(3100) 3.2159\n",
      "(3200) 3.3186\n",
      "(3300) 3.1109\n",
      "(3400) 3.2014\n",
      "(3500) 3.1431\n",
      "(3600) 3.0831\n",
      "(3700) 3.4759\n",
      "(3800) 3.2500\n",
      "(3900) 3.1919\n",
      "(4000) 3.0751\n",
      "(4100) 3.1262\n",
      "(4200) 3.1535\n",
      "(4300) 3.1739\n",
      "(4400) 3.0300\n",
      "(4500) 2.9610\n",
      "(4600) 3.1752\n",
      "(4700) 3.3043\n",
      "(4800) 3.0653\n",
      "(4900) 3.3483\n",
      "(5000) 2.9975\n",
      "(5100) 3.2469\n",
      "(5200) 3.1165\n",
      "(5300) 3.1940\n",
      "(5400) 3.1948\n",
      "(5500) 3.3971\n",
      "(5600) 3.3861\n",
      "(5700) 3.4870\n",
      "(5800) 3.1593\n",
      "(5900) 3.2126\n",
      "(6000) 3.2965\n",
      "(6100) 3.3157\n",
      "(6200) 3.1741\n",
      "(6300) 3.3489\n",
      "(6400) 2.9974\n",
      "(6500) 3.0905\n",
      "(6600) 2.8950\n",
      "(6700) 3.0707\n",
      "(6800) 3.1372\n",
      "(6900) 3.2211\n",
      "(7000) 3.3935\n",
      "(7100) 3.1946\n",
      "(7200) 3.2898\n",
      "(7300) 3.3632\n",
      "(7400) 3.1422\n",
      "(7500) 3.2316\n",
      "(7600) 3.0894\n",
      "(7700) 3.2073\n",
      "(7800) 3.2088\n",
      "(7900) 3.2583\n",
      "(8000) 3.2057\n",
      "(8100) 3.0789\n",
      "(8200) 3.1105\n",
      "(8300) 3.1941\n",
      "(8400) 3.0755\n",
      "(8500) 3.1734\n",
      "(8600) 2.9895\n",
      "(8700) 3.0287\n",
      "(8800) 3.2347\n",
      "(8900) 3.1272\n",
      "(9000) 3.3166\n",
      "(9100) 3.1646\n",
      "(9200) 3.0707\n",
      "(9300) 3.3079\n",
      "(9400) 3.1008\n",
      "(9500) 3.1025\n",
      "(9600) 3.1770\n",
      "(9700) 3.0794\n",
      "(9800) 3.1723\n",
      "(9900) 3.5129\n",
      "(10000) 3.1574\n",
      "===================== Эпоха 4 ====================\n",
      "(100) 2.9923\n",
      "(200) 3.0269\n",
      "(300) 3.2205\n",
      "(400) 3.1585\n",
      "(500) 3.1987\n",
      "(600) 3.1687\n",
      "(700) 3.0034\n",
      "(800) 2.9701\n",
      "(900) 3.1324\n",
      "(1000) 3.0903\n",
      "(1100) 3.0872\n",
      "(1200) 3.4034\n",
      "(1300) 3.1250\n",
      "(1400) 3.2925\n",
      "(1500) 3.1567\n",
      "(1600) 3.0934\n",
      "(1700) 2.9743\n",
      "(1800) 3.1719\n",
      "(1900) 3.2163\n",
      "(2000) 3.0095\n",
      "(2100) 3.1053\n",
      "(2200) 3.0326\n",
      "(2300) 2.9651\n",
      "(2400) 3.1564\n",
      "(2500) 3.2247\n",
      "(2600) 3.0199\n",
      "(2700) 3.1527\n",
      "(2800) 3.1962\n",
      "(2900) 3.1064\n",
      "(3000) 3.1189\n",
      "(3100) 3.1998\n",
      "(3200) 3.1406\n",
      "(3300) 3.0966\n",
      "(3400) 2.9907\n",
      "(3500) 3.1145\n",
      "(3600) 3.2308\n",
      "(3700) 3.0103\n",
      "(3800) 3.1517\n",
      "(3900) 3.0967\n",
      "(4000) 2.9786\n",
      "(4100) 2.9321\n",
      "(4200) 3.1112\n",
      "(4300) 3.3591\n",
      "(4400) 3.1271\n",
      "(4500) 3.1230\n",
      "(4600) 3.1370\n",
      "(4700) 3.0746\n",
      "(4800) 3.1745\n",
      "(4900) 3.0442\n",
      "(5000) 3.3168\n",
      "(5100) 2.9710\n",
      "(5200) 3.2270\n",
      "(5300) 3.1440\n",
      "(5400) 3.1665\n",
      "(5500) 3.1456\n",
      "(5600) 3.1061\n",
      "(5700) 3.0757\n",
      "(5800) 3.1323\n",
      "(5900) 3.1985\n",
      "(6000) 3.1859\n",
      "(6100) 3.1276\n",
      "(6200) 2.9735\n",
      "(6300) 3.0792\n",
      "(6400) 3.0700\n",
      "(6500) 3.0133\n",
      "(6600) 3.0079\n",
      "(6700) 3.3027\n",
      "(6800) 3.3825\n",
      "(6900) 3.0354\n",
      "(7000) 3.0752\n",
      "(7100) 3.0285\n",
      "(7200) 3.1065\n",
      "(7300) 3.0962\n",
      "(7400) 3.0640\n",
      "(7500) 3.0619\n",
      "(7600) 3.0681\n",
      "(7700) 2.9692\n",
      "(7800) 3.0827\n",
      "(7900) 3.2799\n",
      "(8000) 3.0823\n",
      "(8100) 3.2587\n",
      "(8200) 3.0662\n",
      "(8300) 2.9488\n",
      "(8400) 3.0309\n",
      "(8500) 2.9861\n",
      "(8600) 3.0925\n",
      "(8700) 3.0045\n",
      "(8800) 3.3689\n",
      "(8900) 3.0867\n",
      "(9000) 2.8832\n",
      "(9100) 3.0134\n",
      "(9200) 3.1316\n",
      "(9300) 2.9421\n",
      "(9400) 3.0103\n",
      "(9500) 3.0740\n",
      "(9600) 3.1491\n",
      "(9700) 2.9405\n",
      "(9800) 3.0399\n",
      "(9900) 3.1227\n",
      "(10000) 3.1415\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(ds.input_vocabulary_size, 30)\n",
    "attn_decoder1 = AttnDecoderRNN(30, ds.output_vocabulary_size, dropout_p=0.1)\n",
    "\n",
    "#attn_decoder1 = DecoderRNN(len(output_vocab2index)+2, 30)\n",
    "\n",
    "encoder_optimizer = torch.optim.SGD(encoder.parameters(), lr=0.01)\n",
    "decoder_optimizer = torch.optim.SGD(attn_decoder1.parameters(), lr=0.01)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "print_loss_total = 0\n",
    "\n",
    "dl = torch.utils.data.DataLoader(ds, shuffle=True, batch_size=1)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print ('===================== Эпоха %d ====================' % epoch)\n",
    "    for i, ([input_tensor], [target_tensor], _, _) in enumerate(dl):\n",
    "        loss = train_step(input_tensor, target_tensor, encoder,\n",
    "                   attn_decoder1, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "\n",
    "        if (i + 1) % print_loss_n == 0:\n",
    "            print_loss_avg = print_loss_total / print_loss_n\n",
    "            print_loss_total = 0\n",
    "            print('(%d) %.4f' % (i + 1, print_loss_avg))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
